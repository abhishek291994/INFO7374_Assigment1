# -*- coding: utf-8 -*-
"""data_aug.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TlnjwD-BRdrdiEcuHhTT2fulNOyddJ8n
"""

import keras as k 
from keras.datasets import cifar10
from matplotlib import pyplot as p
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras import optimizers
from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from sklearn.metrics import classification_report, confusion_matrix

# Load data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# hyperparameter settings
no_class = 10 
batch_size = 32
epoch = 10

# Data Preprocessing
y_train = k.utils.to_categorical(y_train, no_class)
y_test = k.utils.to_categorical(y_test, no_class)

# pixel values range from 0 to 255 - normalize 
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train  /= 255
x_test /= 255

"""**Feature Standardization: Mean 0, Standard Deviation 1**"""

datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)
datagen.fit(x_train)

def plot_sample():
  for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size):
    for i in range(0, 9):
      p.subplot(330 + 1 + i)
      p.imshow(X_batch[i], cmap=p.get_cmap('gray'))
    return p.show()

plot_sample()

"""ZCA Whitening"""

datagen = ImageDataGenerator(zca_whitening= True)
datagen.fit(x_train)
plot_sample()

"""Random rotations"""

datagen = ImageDataGenerator(rotation_range= 90)
datagen.fit(x_train)
plot_sample()

"""Random Shifts"""

shift = 0.4
datagen = ImageDataGenerator(width_shift_range=shift)
datagen.fit(x_train)
plot_sample()

shift = 0.3
datagen = ImageDataGenerator(width_shift_range=shift,height_shift_range=shift)
datagen.fit(x_train)
plot_sample()

"""Flips"""

datagen = ImageDataGenerator(horizontal_flip= True)
datagen.fit(x_train)
plot_sample()

datagen = ImageDataGenerator(horizontal_flip= True, vertical_flip= True)
datagen.fit(x_train)
plot_sample()

def model_creation():
  model = Sequential()
  model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))
  model.add(Activation('relu'))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Dropout(0.25))
  model.add(Flatten())
  model.add(Dense(512))
  model.add(Activation('relu'))
  model.add(Dropout(0.5))
  model.add(Dense(no_class))
  model.add(Activation('softmax'))
  opt = optimizers.rmsprop(lr=0.0001, decay=1e-6)
  model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])
  return model

cnn_basemodel = model_creation()

cnn_1 = cnn_basemodel.fit(x_train, y_train, batch_size=batch_size, epochs=epoch,validation_data=(x_test,y_test),shuffle=True)
acc = cnn_basemodel.evaluate(x_test, y_test, verbose=1)

print(cnn_1.history.keys())

def plot_modelacc(fit_model):
    with p.style.context('ggplot'):
            p.plot(fit_model.history['acc'])
            p.plot(fit_model.history['val_acc'])
            p.title("MODEL ACCURACY")
            p.xlabel("# of EPOCHS")
            p.ylabel("ACCURACY")
            p.legend(['train', 'test'], loc='upper left')
    return p.show()

def plot_model_loss(fit_model):
    with p.style.context('ggplot'):
            p.plot(fit_model.history['loss'])
            p.plot(fit_model.history['val_loss'])
            p.title("MODEL LOSS")
            p.xlabel("# of EPOCHS")
            p.ylabel("LOSS")
            p.legend(['train', 'test'], loc='upper left')
    return p.show()

plot_modelacc(cnn_1)
plot_model_loss(cnn_1)

print('Test data loss:', acc[0] )
print('Test data accuracy:', acc[1] * 100)

data_aug = ImageDataGenerator(rotation_range=20,
                              width_shift_range=0.1,height_shift_range=0.1,
                              horizontal_flip=True,zca_whitening=False, 
                              featurewise_center=False)

data_aug.fit(x_train,augment = True)

cnn_basemodel.fit_generator(data_aug.flow(x_train, y_train,batch_size=batch_size),
                            epochs=epoch,steps_per_epoch=x_train.shape[0],
                            validation_data=(x_test, y_test)
                           )

acc = cnn_basemodel.evaluate(x_test, y_test, verbose=1)

print('Test data loss:', acc[0] )
print('Test data accuracy:', acc[1] * 100)